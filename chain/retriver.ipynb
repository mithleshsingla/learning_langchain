{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14cf829",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pdf reader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('flow_matching.pdf')\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef868e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='On the Guidance of Flow Matching\\nRuiqi Feng 1 Tailin Wu1 Chenglei Yu1 Wenhao Deng1 Peiyan Hu 2\\nAbstract\\nFlow matching has shown state-of-the-art per-\\nformance in various generative tasks, ranging\\nfrom image generation to decision-making, where\\nguided generation is pivotal. However, the guid-\\nance of flow matching is more general than and\\nthus substantially different from that of its prede-\\ncessor, diffusion models. Therefore, the challenge\\nin guidance for general flow matching remains\\nlargely underexplored. In this paper, we propose\\nthe first framework of general guidance for flow\\nmatching. From this framework, we derive a fam-\\nily of guidance techniques that can be applied\\nto general flow matching. These include a new\\ntraining-free asymptotically exact guidance, novel\\ntraining losses for training-based guidance, and\\ntwo classes of approximate guidance that cover\\nclassical gradient guidance methods as special\\ncases. We theoretically investigate these different'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='training losses for training-based guidance, and\\ntwo classes of approximate guidance that cover\\nclassical gradient guidance methods as special\\ncases. We theoretically investigate these different\\nmethods to give a practical guideline for choosing\\nsuitable methods in different scenarios. Experi-\\nments on synthetic datasets, image inverse prob-\\nlems, and offline reinforcement learning demon-\\nstrate the effectiveness of our proposed guidance\\nmethods and verify the correctness of our flow\\nmatching guidance framework. Code to repro-\\nduce the experiments can be found at here.\\n1. Introduction\\nFlow matching has emerged as a prominent class of gen-\\nerative models. It features the ability to use a vector field\\nto transform samples from a source distribution into sam-\\nples following a target distribution, thus realizing generative\\nmodeling (Lipman et al., 2023). The probability distribution\\nthe samples follow during the flow is called the probability'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='ples following a target distribution, thus realizing generative\\nmodeling (Lipman et al., 2023). The probability distribution\\nthe samples follow during the flow is called the probability\\npath. By designing the probability path in a large design\\nspace, flow matching has shown improved generative model-\\n1Department of Artificial Intelligence, Westlake University,\\nHangzhou, China 2Academy of Mathematics and Systems Science,\\nChinese Academy of Sciences, Beijing, China. Correspondence\\nto: Tailin Wu <wutailin@westlake.edu.cn>.\\ning fidelity as well as higher sampling efficiency in a variety\\nof generative modeling tasks including image generation\\n(Lipman et al., 2023), decision-making (Zheng et al., 2023),\\naudio generation, and molecular structure design (Gat et al.,\\n2024; Chen & Lipman, 2024; Ben-Hamu et al., 2024). Flow\\nmatching substantially extends diffusion models (Ho et al.,\\n2020; Song et al., 2021). Most diffusion models leverage the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='2024; Chen & Lipman, 2024; Ben-Hamu et al., 2024). Flow\\nmatching substantially extends diffusion models (Ho et al.,\\n2020; Song et al., 2021). Most diffusion models leverage the\\nscore matching process (Song & Ermon, 2019; Song et al.,\\n2020; 2021), inherently limiting them to using the Gaussian\\ndistribution as the source distribution to construct a special\\nprobability path. Meanwhile, flow matching can learn the\\nmapping between any source distribution and target distri-\\nbutions (Lipman et al., 2023; 2024; Chen & Lipman, 2024;\\nGat et al., 2024).\\nGuiding flow matching models refers to steering the gen-\\nerated samples toward desired properties, thus sampling\\nfrom a distribution weighted with some objective function\\n(Lu et al., 2023) or conditioned on class labels (Song et al.,\\n2021). It is vital in many generative modeling applications\\n(Song et al., 2023b; Zheng et al., 2023), but in contrary\\nto well-studied guidance in diffusion models (Song et al.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='2021). It is vital in many generative modeling applications\\n(Song et al., 2023b; Zheng et al., 2023), but in contrary\\nto well-studied guidance in diffusion models (Song et al.,\\n2023b; Chung et al., 2023; Dhariwal & Nichol, 2021; Song\\net al., 2023a; Zheng et al., 2024; Lu et al., 2023; Dou &\\nSong, 2024; Trippe et al., 2023), the guidance of flow match-\\ning remains less investigated. Most existing guidance meth-\\nods only apply to a subset of flow matching that assumes the\\nsource distribution to be Gaussian and the probability path to\\nhave a certain simple form (Lipman et al., 2024; Zheng et al.,\\n2023; Pokle et al., 2024; Anonymous, 2025b;c). In these\\ncases, it is allowed to simplify the guidance of flow match-\\ning to be essentially the same as diffusion model guidance,\\nbut flow matching’s power of generating more flexible prob-\\nability paths than diffusion models (Tong et al., 2024; Chen\\n& Lipman, 2024; Gat et al., 2024) is restricted. There have')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6cd8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mithlesh singla\\AppData\\Local\\Temp\\ipykernel_21468\\3745702769.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\mithlesh singla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mithlesh singla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f62fef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FAISS Vector Database\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents[:10], embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c59ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x222dc92e190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e956b4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024; Chen & Lipman, 2024; Ben-Hamu et al., 2024). Flow\\nmatching substantially extends diffusion models (Ho et al.,\\n2020; Song et al., 2021). Most diffusion models leverage the\\nscore matching process (Song & Ermon, 2019; Song et al.,\\n2020; 2021), inherently limiting them to using the Gaussian\\ndistribution as the source distribution to construct a special\\nprobability path. Meanwhile, flow matching can learn the\\nmapping between any source distribution and target distri-\\nbutions (Lipman et al., 2023; 2024; Chen & Lipman, 2024;\\nGat et al., 2024).\\nGuiding flow matching models refers to steering the gen-\\nerated samples toward desired properties, thus sampling\\nfrom a distribution weighted with some objective function\\n(Lu et al., 2023) or conditioned on class labels (Song et al.,\\n2021). It is vital in many generative modeling applications\\n(Song et al., 2023b; Zheng et al., 2023), but in contrary\\nto well-studied guidance in diffusion models (Song et al.,'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"Explain Flow matching \"\n",
    "result=db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a006f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2656472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama llama2\n",
    "llm=OllamaLLM(model=\"qwen2.5:0.5b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5210d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714545c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain Introduction\n",
    "## Create Stuff Docment Chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e8518d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000222DC92E190>, search_kwargs={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrievers: A retriever is an interface that returns documents given\n",
    " an unstructured query. It is more general than a vector store.\n",
    " A retriever does not need to be able to store documents, only to \n",
    " return (or retrieve) them. Vector stores can be used as the backbone\n",
    " of a retriever, but there are other types of retrievers as well. \n",
    " https://python.langchain.com/docs/modules/data_connection/retrievers/   \n",
    "\"\"\"\n",
    "\n",
    "retriever=db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3813751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieval chain:This chain takes in a user inquiry, which is then\n",
    "passed to the retriever to fetch relevant documents. Those documents \n",
    "(and original inputs) are then passed to an LLM to generate a response\n",
    "https://python.langchain.com/docs/modules/chains/\n",
    "\"\"\"\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f804ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retrieval_chain.invoke({\"input\":\"Flowmatching\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5bcc5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Flowmatching',\n",
       " 'context': [Document(id='753ffd30-2dfb-47f8-aa19-d1af052e79a7', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='but flow matching’s power of generating more flexible prob-\\nability paths than diffusion models (Tong et al., 2024; Chen\\n& Lipman, 2024; Gat et al., 2024) is restricted. There have\\nbeen other controlled generation methods for flow matching,\\nwith a notable stream following the paradigm of optimiz-\\ning some objective functions via differentiating through the\\nsampling process (Ben-Hamu et al., 2024; Liu et al., 2023b;\\nAnonymous, 2025d). However, their goal differs from our\\nguidance of weighting the generated distribution. Therefore,\\nthe guidance for flow-matching models remains unrevealed\\nin the rest of the ample design space.\\nTo fill this gap, in this work, we start from a similar assump-\\ntion as diffusion guidance and propose a general framework\\n1\\narXiv:2502.02150v1  [cs.CV]  4 Feb 2025'),\n",
       "  Document(id='8c0d01c3-8138-442f-9b4c-66dacf4949da', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='2024; Chen & Lipman, 2024; Ben-Hamu et al., 2024). Flow\\nmatching substantially extends diffusion models (Ho et al.,\\n2020; Song et al., 2021). Most diffusion models leverage the\\nscore matching process (Song & Ermon, 2019; Song et al.,\\n2020; 2021), inherently limiting them to using the Gaussian\\ndistribution as the source distribution to construct a special\\nprobability path. Meanwhile, flow matching can learn the\\nmapping between any source distribution and target distri-\\nbutions (Lipman et al., 2023; 2024; Chen & Lipman, 2024;\\nGat et al., 2024).\\nGuiding flow matching models refers to steering the gen-\\nerated samples toward desired properties, thus sampling\\nfrom a distribution weighted with some objective function\\n(Lu et al., 2023) or conditioned on class labels (Song et al.,\\n2021). It is vital in many generative modeling applications\\n(Song et al., 2023b; Zheng et al., 2023), but in contrary\\nto well-studied guidance in diffusion models (Song et al.,'),\n",
       "  Document(id='d543cde7-86ab-480d-9848-161c6a3df838', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 1, 'page_label': '2'}, page_content='On the Guidance of Flow Matching\\nof flow matching guidance. From the perspective of this\\nframework, we propose Monte Carlo-based training-free\\nasymptotically exact guidance for flow matching. We also\\npropose different training losses for exact training-based\\nguidance, one of which covers existing losses as special\\ncases (Lu et al., 2023; Anonymous, 2025b). For approxi-\\nmate guidance methods, we can theoretically derive from\\nour framework many famous guidance methods that have ap-\\npeared in the literature, including DPS (Chung et al., 2023),\\nΠGDM (Song et al., 2023a), LGD (Song et al., 2023b), as\\nwell as their flow-matching extensions that are theoretically\\njustified for general flow matching models. We demonstrate\\nthe effectiveness of our proposed method in both synthetic\\ndatasets and decision-making (offline RL) benchmarks. Fur-\\nthermore, more extensive experiments are conducted on\\nimage inverse problems to provide an empirical comparison'),\n",
       "  Document(id='b371bf0c-61a8-4448-bafa-143a8f536a37', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-05T01:37:59+00:00', 'author': 'Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu', 'keywords': 'Machine Learning, ICML', 'moddate': '2025-02-05T01:37:59+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'On the Guidance of Flow Matching', 'trapped': '/False', 'source': 'flow_matching.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}, page_content='On the Guidance of Flow Matching\\nRuiqi Feng 1 Tailin Wu1 Chenglei Yu1 Wenhao Deng1 Peiyan Hu 2\\nAbstract\\nFlow matching has shown state-of-the-art per-\\nformance in various generative tasks, ranging\\nfrom image generation to decision-making, where\\nguided generation is pivotal. However, the guid-\\nance of flow matching is more general than and\\nthus substantially different from that of its prede-\\ncessor, diffusion models. Therefore, the challenge\\nin guidance for general flow matching remains\\nlargely underexplored. In this paper, we propose\\nthe first framework of general guidance for flow\\nmatching. From this framework, we derive a fam-\\nily of guidance techniques that can be applied\\nto general flow matching. These include a new\\ntraining-free asymptotically exact guidance, novel\\ntraining losses for training-based guidance, and\\ntwo classes of approximate guidance that cover\\nclassical gradient guidance methods as special\\ncases. We theoretically investigate these different')],\n",
       " 'answer': \"To answer this question, I'll follow the steps outlined in the task description:\\n\\n1. First, identify the context provided:\\n   - The text discusses flow matching and its limitations.\\n   - It mentions that diffusion models are more flexible than flow matching models (Tong et al., 2024; Chen & Lipman, 2024; Gat et al., 2024).\\n\\n2. Next, identify the main points in the text:\\n   - Flow matching significantly extends diffusion models' abilities.\\n   - Most diffusion models use score matching processes (Song & Ermon, 2019; Song et al., 2020; 2021).\\n   - Flow matching is more versatile as it can learn to match any source distribution with target distributions.\\n   - The text discusses guiding flow matching models and proposes a new training-free asymptotically exact guidance for flow matching.\\n\\n3. Look for specific examples or details that support the main points:\\n   - There are no direct examples provided, but the text mentions the new training-free asymptotic exact guidance used in the proposed framework.\\n\\n4. Summarize the key takeaways from the context and identified information:\\n\\nThe paper introduces a general framework for guiding flow matching models, which can be applied to other generative tasks like image generation and decision-making. The guidance techniques discussed are specific to flow matching and include:\\n1. Monte Carlo-based training-free asymptotically exact guidance\\n2. New training losses for exact training-based guidance (partially covered in the text as special cases)\\n3. Two classes of approximate guidance: one theoretical (classical gradient methods) and another practical (specific examples from literature).\\n\\nThe paper suggests that guiding flow matching models effectively provides more flexible probability paths compared to diffusion model-guided generation.\\n\\nIn conclusion, based on the provided context and identified information:\\n\\nFlowmatching is a generative technique that extends diffusion models' abilities. Most diffusion models use score matching processes, while flow matching can learn target distributions from any source distribution. Guiding flow matching models involves steering generated samples towards desired properties using various guidance techniques including Monte Carlo-based training-free asymptotically exact guidance, new training losses, and two classes of approximate guidance.\\n\\nThe paper proposes a general framework for guiding flow matching models that can be applied to other generative tasks like image generation and decision-making.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d4f744f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To answer this question, I'll follow the steps outlined in the task description:\\n\\n1. First, identify the context provided:\\n   - The text discusses flow matching and its limitations.\\n   - It mentions that diffusion models are more flexible than flow matching models (Tong et al., 2024; Chen & Lipman, 2024; Gat et al., 2024).\\n\\n2. Next, identify the main points in the text:\\n   - Flow matching significantly extends diffusion models' abilities.\\n   - Most diffusion models use score matching processes (Song & Ermon, 2019; Song et al., 2020; 2021).\\n   - Flow matching is more versatile as it can learn to match any source distribution with target distributions.\\n   - The text discusses guiding flow matching models and proposes a new training-free asymptotically exact guidance for flow matching.\\n\\n3. Look for specific examples or details that support the main points:\\n   - There are no direct examples provided, but the text mentions the new training-free asymptotic exact guidance used in the proposed framework.\\n\\n4. Summarize the key takeaways from the context and identified information:\\n\\nThe paper introduces a general framework for guiding flow matching models, which can be applied to other generative tasks like image generation and decision-making. The guidance techniques discussed are specific to flow matching and include:\\n1. Monte Carlo-based training-free asymptotically exact guidance\\n2. New training losses for exact training-based guidance (partially covered in the text as special cases)\\n3. Two classes of approximate guidance: one theoretical (classical gradient methods) and another practical (specific examples from literature).\\n\\nThe paper suggests that guiding flow matching models effectively provides more flexible probability paths compared to diffusion model-guided generation.\\n\\nIn conclusion, based on the provided context and identified information:\\n\\nFlowmatching is a generative technique that extends diffusion models' abilities. Most diffusion models use score matching processes, while flow matching can learn target distributions from any source distribution. Guiding flow matching models involves steering generated samples towards desired properties using various guidance techniques including Monte Carlo-based training-free asymptotically exact guidance, new training losses, and two classes of approximate guidance.\\n\\nThe paper proposes a general framework for guiding flow matching models that can be applied to other generative tasks like image generation and decision-making.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebb012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain-env)",
   "language": "python",
   "name": "langchain-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
